{
    "task": "47fc4a2936669af9ec8f851be845f2d4c7bcca18.txt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "rounds": [
        {
            "code": "package main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"runtime\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Transport represents an underlying network connection.\ntype Transport struct {\n\tID        string\n\terrCh     chan struct{} // Closed when transport error occurs\n\tcloseOnce sync.Once\n\tmu        sync.Mutex // Protects access to isClosed\n\tisClosed  bool\n}\n\n// NewTransport creates a new Transport instance.\nfunc NewTransport(id string) *Transport {\n\tfmt.Printf(\"TRANSPORT %s: Initialized\\n\", id)\n\treturn &Transport{\n\t\tID:    id,\n\t\terrCh: make(chan struct{}),\n\t}\n}\n\n// Error returns a channel that closes when the transport encounters an error.\nfunc (t *Transport) Error() <-chan struct{} {\n\treturn t.errCh\n}\n\n// Close simulates closing the transport connection and signals an error.\nfunc (t *Transport) Close() {\n\tt.closeOnce.Do(func() {\n\t\tt.mu.Lock()\n\t\tdefer t.mu.Unlock()\n\t\tif !t.isClosed {\n\t\t\tfmt.Printf(\"TRANSPORT %s: Closing connection due to error\\n\", t.ID)\n\t\t\tclose(t.errCh) // Signal transport error\n\t\t\tt.isClosed = true\n\t\t}\n\t})\n}\n\n// ClientStream represents an active streaming connection.\ntype ClientStream struct {\n\tID               string\n\tctx              context.Context    // Stream's own context, derived from NewClientStream's input ctx\n\tcancel           context.CancelFunc // Function to cancel stream's context\n\ttransport        *Transport\n\tcleanupOnce      sync.Once\n\tisTransportError bool // Flag to indicate if transport error was the cause\n}\n\n// cleanup performs resource release for the stream.\n// It is idempotent, ensuring cleanup runs only once.\nfunc (cs *ClientStream) cleanup(reason string) {\n\tcs.cleanupOnce.Do(func() {\n\t\tfmt.Printf(\"STREAM %s: Cleaning up stream (reason: %s)\\n\", cs.ID, reason)\n\t\t// In a real application, release network resources, close files, etc.\n\t})\n}\n\n// NewClientStream creates a new client stream and manages its lifecycle.\n// It starts background goroutines to monitor for termination conditions\n// (context cancellation or transport error).\nfunc NewClientStream(ctx context.Context, transport *Transport, wg *sync.WaitGroup) *ClientStream {\n\t// Create a child context for the stream, allowing individual cancellation\n\tstreamCtx, streamCancel := context.WithCancel(ctx)\n\tstreamID := fmt.Sprintf(\"stream-%d\", time.Now().UnixNano()%100000) // Shorter ID for logging\n\n\tcs := &ClientStream{\n\t\tID:        streamID,\n\t\tctx:       streamCtx,\n\t\tcancel:    streamCancel,\n\t\ttransport: transport,\n\t}\n\tfmt.Printf(\"STREAM %s: Created for Transport %s\\n\", cs.ID, transport.ID)\n\n\twg.Add(2) // Add 2 for the two background goroutines managing this stream\n\n\t// Goroutine 1: Monitors for transport errors and triggers stream cancellation\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tselect {\n\t\tcase <-transport.Error():\n\t\t\t// Transport error occurred, mark it and cancel the stream's context\n\t\t\tcs.isTransportError = true\n\t\t\tcs.cancel()\n\t\tcase <-streamCtx.Done():\n\t\t\t// The stream's context was cancelled, either by parent context or explicit cs.cancel()\n\t\t\t// No action needed by this goroutine other than exiting.\n\t\t}\n\t\t// fmt.Printf(\"STREAM %s: Signaler goroutine for Transport %s exited\\n\", cs.ID, transport.ID)\n\t}()\n\n\t// Goroutine 2: Waits for the stream's context to be cancelled and performs cleanup\n\tgo func() {\n\t\tdefer wg.Done()\n\t\t<-streamCtx.Done() // Block until the stream's context is cancelled\n\n\t\treason := \"context cancelled\"\n\t\tif cs.isTransportError {\n\t\t\treason = \"transport error\"\n\t\t}\n\t\tcs.cleanup(reason)\n\t\t// fmt.Printf(\"STREAM %s: Cleanup goroutine for Transport %s exited\\n\", cs.ID, transport.ID)\n\t}()\n\n\treturn cs\n}\n\nfunc main() {\n\tfmt.Println(\"Starting Streaming Client Manager Demo...\")\n\tinitialGoroutines := runtime.NumGoroutine()\n\tfmt.Printf(\"Initial number of goroutines: %d\\n\\n\", initialGoroutines)\n\n\t// Create a root context for the entire application, allowing graceful shutdown\n\tappCtx, appCancel := context.WithCancel(context.Background())\n\tdefer appCancel() // Ensure app context is cancelled when main exits\n\n\tvar wg sync.WaitGroup // WaitGroup to track all stream-related goroutines\n\n\t// --- 1. Create Transports ---\n\tt1 := NewTransport(\"T1\")\n\tt2 := NewTransport(\"T2\")\n\tt3 := NewTransport(\"T3\")\n\tfmt.Println()\n\n\t// --- 2. Create Multiple Client Streams with Different Contexts ---\n\t// Stream 1: Will be explicitly cancelled via its own context (s1Ctx)\n\ts1Ctx, s1Cancel := context.WithCancel(appCtx)\n\t_ = NewClientStream(s1Ctx, t1, &wg)\n\n\t// Stream 2: Will terminate due to Transport T2 error\n\t_ = NewClientStream(appCtx, t2, &wg)\n\n\t// Stream 3: Will terminate when appCtx is cancelled\n\t_ = NewClientStream(appCtx, t3, &wg)\n\n\t// Stream 4: Will be explicitly cancelled via its own context (s4Ctx)\n\ts4Ctx, s4Cancel := context.WithCancel(appCtx)\n\t_ = NewClientStream(s4Ctx, t1, &wg)\n\n\t// Stream 5: Another stream on Transport T2, will also terminate due to T2 error\n\t_ = NewClientStream(appCtx, t2, &wg)\n\n\t// Stream 6: Will terminate due to Transport T1 error (after s1/s4 are done)\n\t_ = NewClientStream(appCtx, t1, &wg)\n\tfmt.Println()\n\n\t// Give some time for streams to be created and goroutines to start\n\ttime.Sleep(200 * time.Millisecond)\n\n\t// --- 3. Demonstrate Stream Termination Scenarios ---\n\n\tfmt.Println(\"\\n--- Scenario A: Explicitly cancelling individual stream contexts ---\")\n\tfmt.Println(\"MAIN: Cancelling stream 1's context (s1Ctx)...\")\n\ts1Cancel() // This should trigger cleanup for Stream 1\n\ttime.Sleep(200 * time.Millisecond)\n\n\tfmt.Println(\"\\nMAIN: Cancelling stream 4's context (s4Ctx)...\")\n\ts4Cancel() // This should trigger cleanup for Stream 4\n\ttime.Sleep(200 * time.Millisecond)\n\n\tfmt.Println(\"\\n--- Scenario B: Triggering transport errors ---\")\n\tfmt.Println(\"MAIN: Closing Transport T2 to trigger errors for streams using it (Stream 2, 5)...\")\n\tt2.Close() // This should trigger cleanup for Stream 2 and Stream 5\n\ttime.Sleep(200 * time.Millisecond)\n\n\tfmt.Println(\"\\nMAIN: Closing Transport T1 to trigger errors for remaining streams using it (Stream 6)...\")\n\tt1.Close() // This should trigger cleanup for Stream 6\n\ttime.Sleep(200 * time.Millisecond)\n\n\tfmt.Println(\"\\n--- Scenario C: Cancelling application-wide context ---\")\n\tfmt.Println(\"MAIN: Cancelling application context (appCtx) to clean up remaining streams (Stream 3)...\")\n\tappCancel() // This should trigger cleanup for Stream 3\n\ttime.Sleep(200 * time.Millisecond)\n\n\tfmt.Println(\"\\nMAIN: All specific actions performed. Waiting for all stream-related background goroutines to finish...\")\n\twg.Wait() // Wait for all goroutines added to the WaitGroup to complete\n\n\tfmt.Println(\"\\nMAIN: Program finished.\")\n\tfinalGoroutines := runtime.NumGoroutine()\n\tfmt.Printf(\"Final number of goroutines: %d (Expected: %d - initial + main goroutine)\\n\", finalGoroutines, initialGoroutines+1)\n\tif finalGoroutines == initialGoroutines+1 {\n\t\tfmt.Println(\"Goroutine check: All background goroutines have been terminated successfully!\")\n\t} else {\n\t\tfmt.Printf(\"Goroutine check: WARNING! Possible goroutine leak detected. Expected %d, found %d.\\n\", initialGoroutines+1, finalGoroutines)\n\t}\n}",
            "passed": true,
            "errors": []
        }
    ],
    "passed": true
}